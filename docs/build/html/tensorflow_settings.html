

<!DOCTYPE html>
<html class="writer-html5" lang="en" >
<head>
  <meta charset="utf-8" />
  
  <meta name="viewport" content="width=device-width, initial-scale=1.0" />
  
  <title>Tensorflow configuration &mdash; USP HPC 0.0.1 documentation</title>
  

  
  <link rel="stylesheet" href="_static/css/theme.css" type="text/css" />
  <link rel="stylesheet" href="_static/pygments.css" type="text/css" />

  
  
    <link rel="shortcut icon" href="_static/favicon_2.ico"/>
  

  
  

  

  
  <!--[if lt IE 9]>
    <script src="_static/js/html5shiv.min.js"></script>
  <![endif]-->
  
    
      <script type="text/javascript" id="documentation_options" data-url_root="./" src="_static/documentation_options.js"></script>
        <script src="_static/jquery.js"></script>
        <script src="_static/underscore.js"></script>
        <script src="_static/doctools.js"></script>
    
    <script type="text/javascript" src="_static/js/theme.js"></script>

    
    <link rel="author" title="About these documents" href="about.html" />
    <link rel="index" title="Index" href="genindex.html" />
    <link rel="search" title="Search" href="search.html" />
    <link rel="next" title="GPU Health Check" href="gpucheck.html" />
    <link rel="prev" title="Code development" href="code_development.html" /> 
</head>

<body class="wy-body-for-nav">

   
  <div class="wy-grid-for-nav">
    
    <nav data-toggle="wy-nav-shift" class="wy-nav-side">
      <div class="wy-side-scroll">
        <div class="wy-side-nav-search"  style="background: white" >
          

          
            <a href="index.html">
          

          
            
            <img src="_static/logo.png" class="logo" alt="Logo"/>
          
          </a>

          

          
<div role="search">
  <form id="rtd-search-form" class="wy-form" action="search.html" method="get">
    <input type="text" name="q" placeholder="Search docs" />
    <input type="hidden" name="check_keywords" value="yes" />
    <input type="hidden" name="area" value="default" />
  </form>
</div>

          
        </div>

        
        <div class="wy-menu wy-menu-vertical" data-spy="affix" role="navigation" aria-label="main navigation">
          
            
            
              
            
            
              <p class="caption"><span class="caption-text">Configuration</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="client_configuration.html">Client configuration</a></li>
<li class="toctree-l1"><a class="reference internal" href="server_configuration.html">Server configuration</a></li>
<li class="toctree-l1"><a class="reference internal" href="install_gdrive.html">Install Google Drive</a></li>
</ul>
<p class="caption"><span class="caption-text">Code Development</span></p>
<ul class="current">
<li class="toctree-l1"><a class="reference internal" href="code_development.html">Code development</a></li>
<li class="toctree-l1 current"><a class="current reference internal" href="#">Tensorflow configuration</a><ul>
<li class="toctree-l2"><a class="reference internal" href="#tensorflow-installation">Tensorflow installation</a></li>
<li class="toctree-l2"><a class="reference internal" href="#save-the-model">Save the model</a></li>
<li class="toctree-l2"><a class="reference internal" href="#data-format">Data format</a></li>
<li class="toctree-l2"><a class="reference internal" href="#openmp-settings">OpenMP settings</a></li>
<li class="toctree-l2"><a class="reference internal" href="#cpu-optimization">CPU optimization</a></li>
<li class="toctree-l2"><a class="reference internal" href="#gpu-optimization">GPU optimization</a></li>
<li class="toctree-l2"><a class="reference internal" href="#compiler-optimization">Compiler optimization</a></li>
<li class="toctree-l2"><a class="reference internal" href="#pipeline-optimization">Pipeline optimization</a></li>
<li class="toctree-l2"><a class="reference internal" href="#distributed-computing">Distributed computing</a></li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="gpucheck.html">GPU Health Check</a></li>
<li class="toctree-l1"><a class="reference internal" href="linux.html">Useful Linux Commands</a></li>
</ul>
<p class="caption"><span class="caption-text">SLURM</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="slurm.html">Slurm</a></li>
<li class="toctree-l1"><a class="reference internal" href="custom_module.html">Working with modules</a></li>
</ul>
<p class="caption"><span class="caption-text">Other Information</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="resources.html">Resources for Researchers</a></li>
<li class="toctree-l1"><a class="reference internal" href="support.html">Getting Support</a></li>
<li class="toctree-l1"><a class="reference internal" href="about.html">About</a></li>
<li class="toctree-l1"><a class="reference internal" href="license.html">License</a></li>
</ul>

            
          
        </div>
        
      </div>
    </nav>

    <section data-toggle="wy-nav-shift" class="wy-nav-content-wrap">

      
      <nav class="wy-nav-top" aria-label="top navigation">
        
          <i data-toggle="wy-nav-top" class="fa fa-bars"></i>
          <a href="index.html">USP HPC</a>
        
      </nav>


      <div class="wy-nav-content">
        
        <div class="rst-content">
        
          

















<div role="navigation" aria-label="breadcrumbs navigation">

  <ul class="wy-breadcrumbs">
    
      <li><a href="index.html" class="icon icon-home"></a> &raquo;</li>
        
      <li>Tensorflow configuration</li>
    
    
      <li class="wy-breadcrumbs-aside">
        
          
            <a href="_sources/tensorflow_settings.rst.txt" rel="nofollow"> View page source</a>
          
        
      </li>
    
  </ul>

  
  <hr/>
</div>
          <div role="main" class="document" itemscope="itemscope" itemtype="http://schema.org/Article">
           <div itemprop="articleBody">
            
  <div class="section" id="tensorflow-configuration">
<h1>Tensorflow configuration<a class="headerlink" href="#tensorflow-configuration" title="Permalink to this headline">¶</a></h1>
<p>Reduce training time with proper Tensorflow and system configuration. This section covers the following topics:</p>
<ol class="arabic simple">
<li><p>Install Tensorflow optimized for performance</p></li>
<li><p>Save the model</p></li>
<li><p>Data format</p></li>
<li><p>OpenMP parameters</p></li>
<li><p>CPU optimization</p></li>
<li><p>GPU optimization</p></li>
<li><p>Compiler optimization</p></li>
<li><p>Distributed computing</p></li>
</ol>
<div class="section" id="tensorflow-installation">
<h2>Tensorflow installation<a class="headerlink" href="#tensorflow-installation" title="Permalink to this headline">¶</a></h2>
<p>Intel created a Tensorflow version optimized for CPU. Use this installation if you won’t use GPU:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span>$ conda install tensorflow -c intel
$ pip install intel-tensorflow==2.4.0
</pre></div>
</div>
<p>Read full instructions at Intel <a class="reference external" href="https://software.intel.com/content/www/us/en/develop/articles/intel-optimization-for-tensorflow-installation-guide.html#Anaconda_main_linux">website</a>.</p>
</div>
<div class="section" id="save-the-model">
<h2>Save the model<a class="headerlink" href="#save-the-model" title="Permalink to this headline">¶</a></h2>
<p>It’s possible to create checkpoints to save the model during training after each epoch, then resume the training from the last checkpoint. This is useful if the training time is larger than the scheduled time, or to prevent hardware failure or broken connection. Saving the model after training for later use is also possible.</p>
<p>Follow the instructions in this <a class="reference external" href="https://www.tensorflow.org/tutorials/keras/save_and_load">tutorial</a> to save the model.</p>
</div>
<div class="section" id="data-format">
<h2>Data format<a class="headerlink" href="#data-format" title="Permalink to this headline">¶</a></h2>
<p>Tensorflow stores and processes image arrays with the channel in the last dimension (channel last), also known as NHWC. The format used by Intel is <a class="reference external" href="https://software.intel.com/content/www/us/en/develop/articles/intel-optimization-for-tensorflow-installation-guide.html#Anaconda_main_linux">channel last</a>, or NCHW. The meaning of each letter is:</p>
<ul class="simple">
<li><p>N: Batch size, indicating number of images in a batch.</p></li>
<li><p>C: Channel, indicating number of channels in an image.</p></li>
<li><p>W: Width, indicating number of pixels in horizontal dimension of an image.</p></li>
<li><p>H: Height, indicating number of pixels in vertical dimension of an image.</p></li>
</ul>
<p>When training on Intel CPU only, force Tensorflow to use channel first with this code:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="kn">import</span> <span class="nn">tensorflow</span> <span class="k">as</span> <span class="nn">tf</span>
<span class="c1"># force channels-first ordering</span>
<span class="n">keras</span><span class="o">.</span><span class="n">backend</span><span class="o">.</span><span class="n">set_image_data_format</span><span class="p">(</span><span class="s1">&#39;channels_first&#39;</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="section" id="openmp-settings">
<h2>OpenMP settings<a class="headerlink" href="#openmp-settings" title="Permalink to this headline">¶</a></h2>
<p>OpenMP implements parallel computing among different processors. <a class="reference external" href="https://software.intel.com/content/www/us/en/develop/articles/guide-to-tensorflow-runtime-optimizations-for-cpu.html">Intel</a> recommends the use these environment variables to configure OpenMP. For convenience, save them in your <cite>~/.bashrc</cite> file or setup in Python.</p>
<ul class="simple">
<li><dl class="simple">
<dt>OMP_NUM_THREADS</dt><dd><ul>
<li><p>Maximum number of threads to use for OpenMP parallel regions if no other value is specified in the application.</p></li>
<li><p>Recommend: start with the number of physical cores/socket on the test system, and try increasing and decreasing</p></li>
</ul>
</dd>
</dl>
</li>
<li><dl class="simple">
<dt>KMP_BLOCKTIME</dt><dd><ul>
<li><p>Time, in milliseconds, that a thread should wait, after completing the execution of a parallel region, before sleeping.</p></li>
<li><p>Recommend: start with 1 and try increasing</p></li>
</ul>
</dd>
</dl>
</li>
<li><dl class="simple">
<dt>KMP_AFFINITY</dt><dd><ul>
<li><p>Restricts execution of certain threads to a subset of the physical processing units in a multiprocessor computer. Only valid if Hyperthreading is enabled.</p></li>
<li><p>Recommend: granularity=fine,verbose,compact,1,0</p></li>
</ul>
</dd>
</dl>
</li>
<li><dl class="simple">
<dt>KMP_SETTINGS</dt><dd><ul>
<li><p>Enables (TRUE) or disables (FALSE) printing of OpenMP run-time library environment variables during execution</p></li>
<li><p>Recommend: Start with TRUE to ensure settings are being utilized, then use as needed</p></li>
</ul>
</dd>
</dl>
</li>
</ul>
<p>Python example:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="kn">import</span> <span class="nn">os</span>
<span class="n">os</span><span class="o">.</span><span class="n">environ</span><span class="p">[</span><span class="s2">&quot;OMP_NUM_THREADS&quot;</span><span class="p">]</span> <span class="o">=</span> <span class="s2">&quot;8&quot;</span>  <span class="c1"># Number of physical cores</span>
<span class="n">os</span><span class="o">.</span><span class="n">environ</span><span class="p">[</span><span class="s2">&quot;KMP_AFFINITY&quot;</span><span class="p">]</span> <span class="o">=</span> <span class="s2">&quot;granularity=fine,compact,1,0&quot;</span>
<span class="n">os</span><span class="o">.</span><span class="n">environ</span><span class="p">[</span><span class="s2">&quot;KMP_BLOCKTIME&quot;</span><span class="p">]</span> <span class="o">=</span> <span class="s2">&quot;0&quot;</span>  <span class="c1">#(or 1)</span>
<span class="n">os</span><span class="o">.</span><span class="n">environ</span><span class="p">[</span><span class="s2">&quot;KMP_SETTINGS&quot;</span><span class="p">]</span> <span class="o">=</span> <span class="s2">&quot;TRUE&quot;</span>
</pre></div>
</div>
</div>
<div class="section" id="cpu-optimization">
<h2>CPU optimization<a class="headerlink" href="#cpu-optimization" title="Permalink to this headline">¶</a></h2>
<p>Set the number of CPU cores that Tensorflow can use with these parameters:</p>
<ul class="simple">
<li><dl class="simple">
<dt>intra_op_parallelism_threads</dt><dd><ul>
<li><p>Number of threads used within an individual op for parallelism</p></li>
<li><p>Recommend: start with the number of cores/socket on the test system, and try increasing and decreasing</p></li>
</ul>
</dd>
</dl>
</li>
<li><dl class="simple">
<dt>inter_op_parallelism_threads</dt><dd><ul>
<li><p>Number of threads used for parallelism between independent operations.</p></li>
<li><p>Recommend: start with the number of physical cores on the test system, and try increasing and decreasing</p></li>
</ul>
</dd>
</dl>
</li>
<li><dl class="simple">
<dt>device_count</dt><dd><ul>
<li><p>Maximum number of devices (CPUs in this case) to use</p></li>
<li><p>Recommend: start with the number of cores/socket on the test system, and try increasing and decreasing</p></li>
</ul>
</dd>
</dl>
</li>
<li><dl class="simple">
<dt>allow_soft_placement</dt><dd><ul>
<li><p>Set to True/enabled to facilitate operations to be placed on CPU instead of GPU</p></li>
</ul>
</dd>
</dl>
</li>
</ul>
<p>Example:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="kn">import</span> <span class="nn">tensorflow</span> <span class="k">as</span> <span class="nn">tf</span>
<span class="n">tf</span><span class="o">.</span><span class="n">config</span><span class="o">.</span><span class="n">threading</span><span class="o">.</span><span class="n">set_inter_op_parallelism_threads</span><span class="p">(</span><span class="mi">8</span><span class="p">)</span>  <span class="c1"># Use 8 physical cores</span>
<span class="n">tf</span><span class="o">.</span><span class="n">config</span><span class="o">.</span><span class="n">threading</span><span class="o">.</span><span class="n">set_intra_op_parallelism_threads</span><span class="p">(</span><span class="mi">8</span><span class="p">)</span>  <span class="c1"># Use 8 physical cores</span>
<span class="n">tf</span><span class="o">.</span><span class="n">config</span><span class="o">.</span><span class="n">set_soft_device_placement</span><span class="p">(</span><span class="kc">True</span><span class="p">)</span>
</pre></div>
</div>
<p>Reference: <a class="reference external" href="https://software.intel.com/content/www/us/en/develop/articles/guide-to-tensorflow-runtime-optimizations-for-cpu.html">https://software.intel.com/content/www/us/en/develop/articles/guide-to-tensorflow-runtime-optimizations-for-cpu.html</a></p>
</div>
<div class="section" id="gpu-optimization">
<h2>GPU optimization<a class="headerlink" href="#gpu-optimization" title="Permalink to this headline">¶</a></h2>
<p>Insert this code in Google Colab to make sure GPU is enabled:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="kn">import</span> <span class="nn">tensorflow</span> <span class="k">as</span> <span class="nn">tf</span>
<span class="c1"># Show available devices: CPU and GPU</span>
<span class="nb">print</span><span class="p">(</span><span class="n">tf</span><span class="o">.</span><span class="n">config</span><span class="o">.</span><span class="n">list_physical_devices</span><span class="p">())</span>

<span class="c1"># Check that we are using a GPU, if not switch runtimes</span>
<span class="c1">#   using Runtime &gt; Change Runtime Type &gt; GPU</span>
<span class="k">assert</span> <span class="nb">len</span><span class="p">(</span><span class="n">tf</span><span class="o">.</span><span class="n">config</span><span class="o">.</span><span class="n">list_physical_devices</span><span class="p">(</span><span class="s1">&#39;GPU&#39;</span><span class="p">))</span> <span class="o">&gt;</span> <span class="mi">0</span>
</pre></div>
</div>
</div>
<div class="section" id="compiler-optimization">
<h2>Compiler optimization<a class="headerlink" href="#compiler-optimization" title="Permalink to this headline">¶</a></h2>
<p><a class="reference external" href="https://www.tensorflow.org/xla">XLA (Accelerated Linear Algebra)</a> is a domain-specific compiler for linear algebra that can accelerate TensorFlow models with potentially no source code changes. Enable XLA in Python or save the environment variable in `` ~/.bashrc``:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="kn">import</span> <span class="nn">os</span>
<span class="n">os</span><span class="o">.</span><span class="n">environ</span><span class="p">[</span><span class="s1">&#39;TF_XLA_FLAGS&#39;</span><span class="p">]</span> <span class="o">=</span> <span class="s1">&#39;--tf_xla_enable_xla_devices&#39;</span>
</pre></div>
</div>
</div>
<div class="section" id="pipeline-optimization">
<h2>Pipeline optimization<a class="headerlink" href="#pipeline-optimization" title="Permalink to this headline">¶</a></h2>
<p>Data input pipeline used during training may impact performance. An efficient pipeline reads data from disk for the next batch while the GPU processes the current batch.</p>
<p>See how to achieve <a class="reference external" href="https://www.tensorflow.org/guide/data_performance">better performance with the tf.data API</a> to build an optimized data pipeline.</p>
</div>
<div class="section" id="distributed-computing">
<h2>Distributed computing<a class="headerlink" href="#distributed-computing" title="Permalink to this headline">¶</a></h2>
<p>Tensorflow can distribute computing in <a class="reference external" href="https://www.tensorflow.org/guide/distributed_training">more than one GPU</a> in the same computer or in <a class="reference external" href="https://www.tensorflow.org/tutorials/distribute/keras">several servers</a>.</p>
<p>This example shows how to enable distributed computing in one or more GPUs or use the default strategy if no GPU is found:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="kn">import</span> <span class="nn">tensorflow</span> <span class="k">as</span> <span class="nn">tf</span>
<span class="c1"># Distributed training: GPU settings</span>
<span class="k">if</span> <span class="n">tf</span><span class="o">.</span><span class="n">config</span><span class="o">.</span><span class="n">list_physical_devices</span><span class="p">(</span><span class="s1">&#39;GPU&#39;</span><span class="p">):</span>
  <span class="n">strategy</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">distribute</span><span class="o">.</span><span class="n">MirroredStrategy</span><span class="p">()</span>
<span class="k">else</span><span class="p">:</span>  <span class="c1"># use default strategy</span>
  <span class="n">strategy</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">distribute</span><span class="o">.</span><span class="n">get_strategy</span><span class="p">()</span>
</pre></div>
</div>
<p>Then use the <strong>strategy</strong> to create the model, optimizer and compile the model:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="k">with</span> <span class="n">strategy</span><span class="o">.</span><span class="n">scope</span><span class="p">():</span>
        <span class="n">optimizer</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">keras</span><span class="o">.</span><span class="n">optimizers</span><span class="o">.</span><span class="n">SGD</span><span class="p">()</span>
        <span class="n">model</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">keras</span><span class="o">.</span><span class="n">Sequential</span><span class="p">([</span><span class="n">tf</span><span class="o">.</span><span class="n">keras</span><span class="o">.</span><span class="n">layers</span><span class="o">.</span><span class="n">Dense</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="n">input_shape</span><span class="o">=</span><span class="p">(</span><span class="mi">1</span><span class="p">,))])</span>
        <span class="n">model</span><span class="o">.</span><span class="n">compile</span><span class="p">(</span><span class="n">loss</span><span class="o">=</span><span class="s1">&#39;mse&#39;</span><span class="p">,</span> <span class="n">optimizer</span><span class="o">=</span><span class="n">optimizer</span><span class="p">)</span>
</pre></div>
</div>
<p>See <a class="reference external" href="https://www.tensorflow.org/guide/distributed_training">distributed training with TensorFlow</a> for complete explanation about distributed computing.</p>
</div>
</div>


           </div>
           
          </div>
          <footer>
    <div class="rst-footer-buttons" role="navigation" aria-label="footer navigation">
        <a href="gpucheck.html" class="btn btn-neutral float-right" title="GPU Health Check" accesskey="n" rel="next">Next <span class="fa fa-arrow-circle-right" aria-hidden="true"></span></a>
        <a href="code_development.html" class="btn btn-neutral float-left" title="Code development" accesskey="p" rel="prev"><span class="fa fa-arrow-circle-left" aria-hidden="true"></span> Previous</a>
    </div>

  <hr/>

  <div role="contentinfo">
    <p>
        &#169; Copyright 2021, Victor Ivamoto.

    </p>
  </div>
    
    
    
    Built with <a href="https://www.sphinx-doc.org/">Sphinx</a> using a
    
    <a href="https://github.com/readthedocs/sphinx_rtd_theme">theme</a>
    
    provided by <a href="https://readthedocs.org">Read the Docs</a>. 

</footer>
        </div>
      </div>

    </section>

  </div>
  

  <script type="text/javascript">
      jQuery(function () {
          SphinxRtdTheme.Navigation.enable(true);
      });
  </script>

  
  
    
   

</body>
</html>